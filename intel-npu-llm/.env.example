# Intel NPU LLM Server - Environment Configuration
# Copy this file to .env and fill in your values

# HuggingFace Token (required for gated models like Llama)
# Get your token at: https://huggingface.co/settings/tokens
# Make sure to accept the Llama license at: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct
HF_TOKEN=hf_your_token_here
